在C++标准库中，`std::unordered_set`和`std::unordered_map`底层数据结构使用哈希表，`std::set`和`std::map`底层数据结构使用红黑树，这里仅讨论前者。

为方便理解哈希算法，从一个简单问题出发。考虑维护一个值域为`0~N`（`N`不太大）的数集，要求若干操作，有两种，一种是查找，查找某个数字是否出现过，另一种是出现，表示该数字出现。一种方法是创建一个布尔数组`s[N + 1]`并初始化为`false`，如果出现一个数字`x`，令`s[x] = true`，如果查询一个数字`x`，检测`s[x]`是否为`true`即可。这就是**桶哈希**。

实际的哈希表就是从这种方法中出发：对于要维护的元素，通过一个函数（上面的例子相当于一个 $f(x) = x$ 的函数）将该元素映射到一个整数值，然后维护这个整数值即而维护元素。

上面提到的函数就是**哈希函数**。

**哈希冲突**：如果对哈希函数 $f(x)$ 出现 $x_1$ 和 $x_2$ ，它们 $f(x_1) = f(x_2)$ ，就出现了问题，该把这个元素放在哪里呢？
为解决这个问题，就有两种哈希算法：**拉链法**和**开放寻址法**。

+ 对哈希函数的要求：

# 拉链法

# 开放寻址法

开放寻址法怎么解决哈希冲突呢？有**一次探测**、**二次探测**、`Robin Hood`等等算法。

开放寻址法还有一个问题，就是怎么删除元素，因为拉链法的删除有链表的属性，删除是常数的，但开放寻址法不行。

+ 开放寻址法的删除：
  + 将之后所有同哈希值的桶往前移动（这就很像数据结构线性表的删除）
  + 墓碑：将删除的桶特殊标记

+ 拉链法的缺点是对缓存不友好，而开放寻址法，特别是一次探测，则对缓存很友好。

## 一次探测

+ 不会出现哈希冲突

    直接定义布尔数组
    insert: data[hash(value)] = true;
    contain: return data[hash(value)];

+ 会出现哈希冲突, 使用一次探测解决

    insert: 循环找到空的位置, 对应位置插入值
    contain: 对应位置有值不保证匹配,比较对应的值,直到找到或者遇到空位置(真的没有)
    >我们发现如果哈希表插入慢, 查询会死循环, 所以需要对哈希表进行扩充, 暂不考虑

+ 支持删除
  
    >我们要保证一个值唯一的在表中
    delete: 对应位置特殊标记, 此时data中有三种类型, 空, 特殊(即墓碑), 值
    insert: 遇到空或者特殊标记都可以插入
    contain: 遇到空不能停止. 应为可能下面的情况

    ```
                        x
    hash : [a]   [a]  [a] [a]  [b]  [b]  [a]
    value: [s1] [s2] [s3] [s4] [s5] [s6] [s7]
    ```

    我们发现对于标记的地方，如果只是简单的置空，则后面再查哈希值为a时后空过去后面的a
    所以删除时仅仅是标记, 同时检查时只有真的空才停止, 遇到墓碑继续找

+ 对于扩容

    哈希表认为时间复杂度是O(1)的嘛，我们发现如果扩容(无论用什么方法),
    总是将一个插入到表中的元素重新插入到另一个表中,
    这个均摊O(1)的时间复杂度是怎么来的呢?

    对于扩容, 有两个常量, 装填因子(k)和扩容倍数(d),
    即插入的值占哈希表大小的占比超过装填因子则进行扩容, 哈希表扩大扩容倍数大小

    所以对于插入的n个元素,
    其中
    ```
    (d ^ 0        - 0)                 * k * n个元素会移动log_d(n) - 0次
    (d ^ 1        - d ^ 0)             * k * n个元素会移动log_d(n) - 1次
    (d ^ 2        - d ^ 1)             * k * n个元素会移动log_d(n) - 2次
    (d ^ 3        - d ^ 2)             * k * n个元素会移动log_d(n) - 3次
    ...
    (d ^ log_d(n) - d ^ (log_d(n) - 1))* k * n个元素会移动1           次
    ```
    推导式确实是上面，但是具体怎么推导到最后的1的我确实不知道。

+ 考虑下扩容d的装填因子
    >一般来说，装填因子是3/4，扩容是一倍, 特别小的情况再讨论

    其实反而容易, 自然实现

+ 引入并发

    普通的读写锁

## Robin Hood算法

对于 一次探测 开放寻址法 墓碑法删除 的 哈希表，随着元素和操作越来越多，查找效率会变得越来越差，因为元素离它本来要插入的位置越来越远。为了解决这个问题，`Robin Hood`算法出现。

# Swiss Table
